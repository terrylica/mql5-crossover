#!/usr/bin/env python3
"""
Research Python statistical modules for financial time series normalization.

Focus areas:
1. Percentile/quantile calculation methods
2. Rolling window statistics
3. Distribution fitting and outlier detection
4. Performance characteristics
"""

# /// script
# requires-python = ">=3.12"
# dependencies = [
#     "pandas>=2.2.0",
#     "numpy>=1.26.0",
#     "scipy>=1.11.0",
#     "bottleneck>=1.3.0",
#     "numba>=0.59.0",
#     "scikit-learn>=1.3.0",
# ]
# ///

import numpy as np
import pandas as pd
import time
from pathlib import Path
from typing import Callable
import bottleneck as bn
from numba import jit


def load_data() -> np.ndarray:
    """Load CCI data."""
    data_path = Path("/Users/terryli/Library/Application Support/CrossOver/Bottles/MetaTrader 5/drive_c/Program Files/MetaTrader 5/MQL5/Files/cci_debug_EURUSD_PERIOD_M12_2025.10.29.csv")
    df = pd.read_csv(data_path, sep=';')
    return df['cci'].values


def benchmark_percentile_methods(data: np.ndarray, window: int = 120) -> dict:
    """
    Benchmark different percentile calculation methods.

    Libraries/methods:
    1. NumPy - np.percentile
    2. Pandas - rolling().quantile()
    3. SciPy - stats.percentileofscore
    4. Bottleneck - bn.move_median, bn.move_rank
    5. Custom Numba JIT implementation
    """
    print("="*70)
    print("BENCHMARK 1: Percentile Calculation Methods")
    print("="*70)

    n_samples = 10000
    test_data = data[:n_samples]

    results = {}

    # Method 1: NumPy percentile (naive loop)
    print("\n1. NumPy percentile (naive loop)")
    start = time.time()
    scores_np = []
    for i in range(window, len(test_data)):
        win = test_data[i-window:i]
        score = np.sum(win < test_data[i]) / len(win)
        scores_np.append(score)
    time_np = time.time() - start
    print(f"   Time: {time_np:.3f}s ({time_np/len(scores_np)*1000:.3f}ms per calc)")
    results['numpy'] = {'time': time_np, 'per_calc': time_np/len(scores_np)}

    # Method 2: Pandas rolling quantile
    print("\n2. Pandas rolling().quantile()")
    start = time.time()
    series = pd.Series(test_data)
    # Calculate percentile rank using rolling mean of (value < window)
    rolling_scores = series.rolling(window).apply(
        lambda x: np.sum(x[:-1] < x.iloc[-1]) / (len(x) - 1) if len(x) > 1 else 0.5,
        raw=False
    )
    time_pd = time.time() - start
    print(f"   Time: {time_pd:.3f}s ({time_pd/len(rolling_scores)*1000:.3f}ms per calc)")
    results['pandas'] = {'time': time_pd, 'per_calc': time_pd/len(rolling_scores)}

    # Method 3: SciPy percentileofscore (loop)
    print("\n3. SciPy stats.percentileofscore")
    from scipy import stats
    start = time.time()
    scores_scipy = []
    for i in range(window, min(len(test_data), window + 1000)):  # Limit to 1000 for speed
        win = test_data[i-window:i]
        score = stats.percentileofscore(win, test_data[i], kind='weak') / 100
        scores_scipy.append(score)
    time_scipy = time.time() - start
    print(f"   Time: {time_scipy:.3f}s ({time_scipy/len(scores_scipy)*1000:.3f}ms per calc)")
    print(f"   Note: Limited to 1000 calculations (too slow for full dataset)")
    results['scipy'] = {'time': time_scipy, 'per_calc': time_scipy/len(scores_scipy)}

    # Method 4: Bottleneck move_rank
    print("\n4. Bottleneck bn.move_rank")
    start = time.time()
    # move_rank returns rank, need to normalize
    ranks = bn.move_rank(test_data[:n_samples], window=window, axis=0)
    scores_bn = ranks / window
    time_bn = time.time() - start
    print(f"   Time: {time_bn:.3f}s ({time_bn/len(scores_bn)*1000:.3f}ms per calc)")
    results['bottleneck'] = {'time': time_bn, 'per_calc': time_bn/len(scores_bn)}

    # Method 5: Numba JIT optimized
    print("\n5. Numba JIT optimized")

    @jit(nopython=True)
    def percentile_rank_jit(data: np.ndarray, window: int) -> np.ndarray:
        n = len(data)
        scores = np.empty(n - window)
        for i in range(window, n):
            count_below = 0
            current = data[i]
            for j in range(i - window, i):
                if data[j] < current:
                    count_below += 1
            scores[i - window] = count_below / window
        return scores

    # Warm up JIT
    _ = percentile_rank_jit(test_data[:500], 50)

    start = time.time()
    scores_jit = percentile_rank_jit(test_data, window)
    time_jit = time.time() - start
    print(f"   Time: {time_jit:.3f}s ({time_jit/len(scores_jit)*1000:.3f}ms per calc)")
    results['numba'] = {'time': time_jit, 'per_calc': time_jit/len(scores_jit)}

    # Summary
    print("\n" + "="*70)
    print("PERFORMANCE SUMMARY (sorted by speed)")
    print("="*70)
    sorted_results = sorted(results.items(), key=lambda x: x[1]['time'])
    baseline = sorted_results[0][1]['time']
    for name, stats in sorted_results:
        speedup = baseline / stats['time']
        print(f"{name:15s}: {stats['time']:6.3f}s  "
              f"({stats['per_calc']*1000:7.4f}ms/calc)  "
              f"[{speedup:.1f}x faster than slowest]")

    return results


def benchmark_rolling_statistics(data: np.ndarray, window: int = 120) -> dict:
    """
    Benchmark rolling window statistics.

    Focus on median, quantiles, IQR calculation.
    """
    print("\n" + "="*70)
    print("BENCHMARK 2: Rolling Window Statistics")
    print("="*70)

    n_samples = 10000
    test_data = data[:n_samples]

    results = {}

    # Method 1: Pandas rolling (naive)
    print("\n1. Pandas rolling() - median + quantiles")
    start = time.time()
    series = pd.Series(test_data)
    rolling_median = series.rolling(window).median()
    rolling_q1 = series.rolling(window).quantile(0.25)
    rolling_q3 = series.rolling(window).quantile(0.75)
    rolling_iqr = rolling_q3 - rolling_q1
    time_pd = time.time() - start
    print(f"   Time: {time_pd:.3f}s")
    results['pandas'] = {'time': time_pd}

    # Method 2: Bottleneck move_median
    print("\n2. Bottleneck bn.move_median")
    start = time.time()
    rolling_median_bn = bn.move_median(test_data, window=window)
    time_bn = time.time() - start
    print(f"   Time: {time_bn:.3f}s")
    results['bottleneck'] = {'time': time_bn}

    # Method 3: NumPy with Numba JIT
    print("\n3. Numba JIT - median + IQR")

    @jit(nopython=True)
    def rolling_stats_jit(data: np.ndarray, window: int) -> tuple:
        n = len(data)
        medians = np.empty(n)
        q1s = np.empty(n)
        q3s = np.empty(n)

        for i in range(window, n):
            win = data[i-window:i]
            sorted_win = np.sort(win)
            medians[i] = sorted_win[window // 2]
            q1s[i] = sorted_win[window // 4]
            q3s[i] = sorted_win[3 * window // 4]

        return medians, q1s, q3s

    # Warm up
    _ = rolling_stats_jit(test_data[:500], 50)

    start = time.time()
    medians_jit, q1s_jit, q3s_jit = rolling_stats_jit(test_data, window)
    iqr_jit = q3s_jit - q1s_jit
    time_jit = time.time() - start
    print(f"   Time: {time_jit:.3f}s")
    results['numba'] = {'time': time_jit}

    # Summary
    print("\n" + "="*70)
    print("ROLLING STATISTICS SUMMARY")
    print("="*70)
    sorted_results = sorted(results.items(), key=lambda x: x[1]['time'])
    baseline = sorted_results[-1][1]['time']
    for name, stats in sorted_results:
        speedup = baseline / stats['time']
        print(f"{name:15s}: {stats['time']:6.3f}s  [{speedup:.1f}x speedup vs baseline]")

    return results


def test_online_algorithms() -> dict:
    """
    Test online/streaming algorithms for percentile estimation.

    These maintain approximate percentiles with O(1) updates.
    """
    print("\n" + "="*70)
    print("BENCHMARK 3: Online/Streaming Percentile Algorithms")
    print("="*70)

    print("\nüìö LIBRARY RECOMMENDATIONS:")
    print("\n1. streaming-percentiles (PyPI)")
    print("   - T-Digest, P¬≤, GK algorithms")
    print("   - O(1) updates, O(log n) memory")
    print("   - Best for real-time/incremental updates")
    print("   - Installation: pip install streaming-percentiles")

    print("\n2. datasketch (PyPI)")
    print("   - Probabilistic data structures")
    print("   - KLL sketch for quantiles")
    print("   - Very memory efficient")
    print("   - Installation: pip install datasketch")

    print("\n3. ddsketch (PyPI)")
    print("   - Datadog's DDSketch algorithm")
    print("   - Relative error guarantees")
    print("   - Mergeable sketches")
    print("   - Installation: pip install ddsketch")

    print("\n‚ö†Ô∏è  TRADE-OFFS:")
    print("   - Approximations vs exact percentiles")
    print("   - Memory efficiency vs accuracy")
    print("   - Good for extreme quantiles (P99, P99.9)")
    print("   - May not be necessary for P30, P70 (our use case)")

    return {}


def outlier_detection_methods(data: np.ndarray) -> dict:
    """
    Test outlier detection methods relevant to CCI normalization.
    """
    print("\n" + "="*70)
    print("BENCHMARK 4: Outlier Detection Methods")
    print("="*70)

    from scipy import stats

    sample_data = data[10000:11000]

    results = {}

    # Method 1: IQR method
    print("\n1. IQR Method (Tukey's Fences)")
    q1 = np.percentile(sample_data, 25)
    q3 = np.percentile(sample_data, 75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    outliers_iqr = (sample_data < lower_bound) | (sample_data > upper_bound)
    print(f"   Bounds: [{lower_bound:.1f}, {upper_bound:.1f}]")
    print(f"   Outliers: {outliers_iqr.sum()} ({outliers_iqr.sum()/len(sample_data)*100:.1f}%)")
    results['iqr'] = {'count': outliers_iqr.sum(), 'pct': outliers_iqr.sum()/len(sample_data)}

    # Method 2: Z-score method
    print("\n2. Z-Score Method (|z| > 3)")
    z_scores = np.abs(stats.zscore(sample_data))
    outliers_z = z_scores > 3
    print(f"   Outliers: {outliers_z.sum()} ({outliers_z.sum()/len(sample_data)*100:.1f}%)")
    results['zscore'] = {'count': outliers_z.sum(), 'pct': outliers_z.sum()/len(sample_data)}

    # Method 3: Modified Z-score (MAD)
    print("\n3. Modified Z-Score (MAD-based)")
    median = np.median(sample_data)
    mad = np.median(np.abs(sample_data - median))
    modified_z_scores = 0.6745 * (sample_data - median) / mad
    outliers_mad = np.abs(modified_z_scores) > 3.5
    print(f"   Outliers: {outliers_mad.sum()} ({outliers_mad.sum()/len(sample_data)*100:.1f}%)")
    results['mad'] = {'count': outliers_mad.sum(), 'pct': outliers_mad.sum()/len(sample_data)}

    # Method 4: Isolation Forest (scikit-learn)
    print("\n4. Isolation Forest (scikit-learn)")
    from sklearn.ensemble import IsolationForest
    clf = IsolationForest(contamination=0.1, random_state=42)
    outliers_if = clf.fit_predict(sample_data.reshape(-1, 1)) == -1
    print(f"   Outliers: {outliers_if.sum()} ({outliers_if.sum()/len(sample_data)*100:.1f}%)")
    results['isolation_forest'] = {'count': outliers_if.sum(), 'pct': outliers_if.sum()/len(sample_data)}

    print("\nüí° RECOMMENDATION FOR CCI:")
    print("   - Percentile rank is already robust to outliers")
    print("   - No need for explicit outlier removal")
    print("   - IQR method useful for regime change detection")

    return results


def main():
    """Run all benchmarks."""
    print("="*70)
    print("PYTHON STATISTICAL MODULES FOR FINANCIAL TIME SERIES")
    print("="*70)
    print("\nLoading CCI data...")

    data = load_data()
    print(f"Loaded {len(data):,} bars")

    # Run benchmarks
    perc_results = benchmark_percentile_methods(data, window=120)
    rolling_results = benchmark_rolling_statistics(data, window=120)
    online_results = test_online_algorithms()
    outlier_results = outlier_detection_methods(data)

    # Final recommendations
    print("\n" + "="*70)
    print("üéØ FINAL RECOMMENDATIONS")
    print("="*70)

    print("\n1. FOR MQL5 IMPLEMENTATION (Production):")
    print("   ‚úÖ Use naive percentile rank loop (already fast in compiled MQL5)")
    print("   ‚úÖ Window size: 120 bars (good balance)")
    print("   ‚úÖ No external dependencies needed")

    print("\n2. FOR PYTHON PROTOTYPING:")
    print("   ‚úÖ Bottleneck (bn.move_rank) - Fastest for single-window")
    print("   ‚úÖ Numba JIT - Most flexible, easy to customize")
    print("   ‚úÖ Pandas - Good for exploratory analysis")

    print("\n3. FOR PRODUCTION PYTHON (if needed):")
    print("   ‚úÖ Numba JIT implementation")
    print("   ‚úÖ Can handle multi-scale ensemble efficiently")
    print("   ‚úÖ ~100-500x faster than pure Python")

    print("\n4. ADVANCED FEATURES (future work):")
    print("   - streaming-percentiles: For real-time updates")
    print("   - datasketch: For memory-constrained environments")
    print("   - scipy.stats: For distribution fitting")

    print("\n5. NOT RECOMMENDED:")
    print("   ‚ùå scipy.stats.percentileofscore (too slow)")
    print("   ‚ùå Online sketching algorithms (overkill for our use case)")
    print("   ‚ùå Explicit outlier removal (percentile rank already robust)")


if __name__ == "__main__":
    main()
